{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/israelgonzalezb/neuromatch-dl/blob/main/tutorials/W3D2_DlThinking2/student/W3D2_Tutorial1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "fRv6ndZuEDFR"
      },
      "source": [
        "# Tutorial 1: Deep Learning Thinking 2: Architectures and Multimodal DL thinking\n",
        "\n",
        "**Week 3, Day 2: DL Thinking 2**\n",
        "\n",
        "**By Neuromatch Academy**\n",
        "\n",
        "\n",
        "__Content creators:__ Konrad Kording, Lyle ungar\n",
        " \n",
        "__Content reviewers:__ Kelson Shilling-Scrivo\n",
        "\n",
        "__Content editors:__ Kelson Shilling-Scrivo\n",
        "\n",
        "__Production editors:__ Spiros Chavlis "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "avScIVVpEDGF"
      },
      "source": [
        "<p align='center'><img src='https://github.com/NeuromatchAcademy/widgets/blob/master/sponsors.png?raw=True'/></p>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "aWGU-JL_EDGL"
      },
      "source": [
        "---\n",
        "# Tutorial Objectives\n",
        "\n",
        "In this tutorial, you will practice thinking like a deep learning practioner and figure out how to design architectures for different scenarios. \n",
        "\n",
        "By the end of this tutorial, you will be better able to:\n",
        "\n",
        "* Know how to proceed when low on data\n",
        "* Have a toolbox of what to do in non-standard situations\n",
        "\n",
        "We will also continue to see how to get relevant information out of domain experts, arguably the central skill of DL and how to convert insights into domains into the logic of actual approaches."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "MAv9aHfpEDGN"
      },
      "outputs": [],
      "source": [
        "# @title Tutorial slides\n",
        "\n",
        "from IPython.display import IFrame\n",
        "IFrame(src=f\"https://mfr.ca-1.osf.io/render?url=https://osf.io/teq6v/?direct%26mode=render%26action=download%26mode=render\", width=854, height=480)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "o0N8EA-dEDGO"
      },
      "source": [
        "These are the slides for all videos in this tutorial. If you want to download locally the slides, click [here](https://osf.io/teq6v/download)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BBKlQY4wEDGP"
      },
      "source": [
        "---\n",
        "# Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "xsNe6p2UEDGP"
      },
      "outputs": [],
      "source": [
        "# @title Install dependencies\n",
        "!pip install git+https://github.com/NeuromatchAcademy/evaltools --quiet\n",
        "\n",
        "from evaltools.airtable import AirtableForm\n",
        "atform = AirtableForm('appn7VdPRseSoMXEG', 'W3D2_T1','https://portal.neuromatchacademy.org/api/redirect/to/e1f5e678-eaf8-4c24-9018-d758b50314d5')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "CqjFeTrPEDGQ"
      },
      "source": [
        "---\n",
        "# Section 1: Intro Deep Learning Thinking 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "S6tmDk6CEDGR"
      },
      "outputs": [],
      "source": [
        "# @title Video 1: Intro to DL Thinking 2\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"I0PNDBF0Sxg\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 1: Intro to DL Thinking 2')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BWj486XMEDGS"
      },
      "source": [
        "Like deep learning thinking 1 last week, this tutorial is a bit different from others - there will be no coding! Instead, you will watch a series of vignettes about various scenarios where you want to use a neural network. This tutorial will focus on various architectures and multimodal thinking.\n",
        "\n",
        "Each section below will start with a vignette where either Lyle or Konrad is trying to figure out how to set up a neural network for a specific problem. Try to think of questions you want to ask them as you watch, then pay attention to what questions Lyle and Konrad are asking. Were they what you would have asked? How do their questions help quickly clarify the situation?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "KyrUPld0EDGT"
      },
      "source": [
        "---\n",
        "# Section 2: Getting More Data "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "-lWjxq9uEDGT"
      },
      "outputs": [],
      "source": [
        "# @title Video 2: Getting More Data Vignette\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"Gswf3m0lAro\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 2: Getting More Data Vignette')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "tVPSQMVQEDGU"
      },
      "source": [
        "Konrad wants to build a neural network that classifies images based on the objects contained within them. He needs more data to help him train an accurate network, but buying more images is costly. He needs a different solution."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "TMsUa5AWEDGV"
      },
      "source": [
        "## Think! 1: Designing a strategy to get more data\n",
        "\n",
        "Given everything you know, how would you design a strategy to get some more data (pairs of images and the label of the object they are of) for the image classification neural network that Konrad is training? Be specific & write down a procedure.\n",
        "\n",
        "Please discuss as a group. If you get stuck, you can uncover the hints below one at a time. Please spend some time discussing before uncovering the next hint, though! You are being real deep learning scientists now, and the answers won't be easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "niGWXhYfEDGV"
      },
      "outputs": [],
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q1' , text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "IYX0J2HyEDGW"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 1 </font></summary>\n",
        "\n",
        "Look at a few photos of dogs (use an image search engine). How are they similar? How are they different? What makes them all be dogs?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "VMw8rmefEDGW"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 2 </font></summary>\n",
        "\n",
        "We don't need to obtain any new images in order to give more examples of each object to our neural network."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "_9dk4n8yEDGW"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 3 </font></summary>\n",
        "\n",
        "Think about color, orientation, flipping, pixel noise, color noise, shearing, contrast, brightness, scaling"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NrHu9bS2EDGX"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 4 </font></summary>\n",
        "\n",
        "Discuss where each of these ideas will break down. Can too much of a good thing be good?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "-DXZ2-08EDGX"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for solution  </font></summary>\n",
        "\n",
        "Instead of collecting new data, we can create multiple examples for the neural network of each of our existing images by changing things like flipping them horizontally, shifting them horizontally or vertically by some number of pixels, scaling them to be larger or smaller (and cropping), rotating them, and changing their contrast and brightness.\n",
        "\n",
        "This is called data augmentation and is a very commonly used and important strategy for training neural networks. \n",
        "\n",
        "Importantly, we need to be careful about the amount we change each image, and we still want them to be useful training images! Let's say you have a photo of a dog, and you scale it to be 1000x bigger and crop the middle out. You'd have just an image of fur - this would not be very useful as a training example on how to classify dogs. So we want to change factors about the images but not so much that they are no longer recognizable as the original object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "8RHK-W6wEDGX"
      },
      "outputs": [],
      "source": [
        "# @title Video 3: Getting More Data Wrap-up\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"GcGJNF-wIb0\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 3: Getting More Data Wrap-up')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "m5Ewank9EDGY"
      },
      "source": [
        "Check out the papers mentioned in the above video:\n",
        "\n",
        "- [The Effects of Regularization and Data Augmentation are Class Dependent ](https://arxiv.org/abs/2204.03632#:~:text=The%20Effects%20of%20Regularization%20and%20Data%20Augmentation%20are%20Class%20Dependent,-Randall%20Balestriero%2C%20Leon&text=Abstract%3A%20Regularization%20is%20a%20fundamental,by%20constraining%20a%20model's%20complexity)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "hG9EY02yEDGY"
      },
      "source": [
        "## (Bonus) Think!: Class-based strategies \n",
        "\n",
        "Discuss how you may want to vary these strategies based on the class of the object/images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BUnQXWRpEDGY"
      },
      "source": [
        "---\n",
        "# Section 3: Detecting Tumors - what to do if there still isn't enough data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "pOKFzSOMEDGZ"
      },
      "outputs": [],
      "source": [
        "# @title Video 4: Detecting Tumors Vignette\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=\"BV1Fr4y177An\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=\"dRRRuiQctXY\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 4: Detecting Tumors Vignette')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "FxdsruTQEDGZ"
      },
      "outputs": [],
      "source": [
        "# @title Video 5: Detecting Tumors Set-up\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"0UZ2qia2pG4\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 5: Detecting Tumors Set-up')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "y2d11rtoEDGZ"
      },
      "source": [
        "Konrad works for a hospital and wants to train a neural network to detect tumors in brain scans automatically. This type of tumor is pretty rare, which is great for humanity but means we only have a few thousand training examples for our neural network. This isn't enough. \n",
        "\n",
        "Even with adding in images of other types of tumors, we don't have enough data. We have a lot of images of other things in ImageNet, like cats and dogs, though! Maybe we can use that?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "UBajy38WEDGa"
      },
      "source": [
        "## Think! 2: Designing a strategy for detecting tumors \n",
        "\n",
        "Given everything you know, how would you design a strategy to be able to train an accurate tumor-detecting neural network? Be specific & write down a procedure.\n",
        "\n",
        "Please discuss as a group. If you get stuck, you can uncover the hints below one at a time. Please spend some time discussing before uncovering the next hint, though! You are being real deep learning scientists now, and the answers won't be easy."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "25Y-5FEMEDGa"
      },
      "outputs": [],
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q2' , text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "yFNMUkVrEDGa"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 1 </font></summary>\n",
        "\n",
        "Data augmentation is always something to consider"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "45Gm57dQEDGb"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 2</font></summary>\n",
        "\n",
        "A human learning to detect tumors is not learning how to see from scratch just based on the tumor images."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "5NBB2wTNEDGk"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 3</font></summary>\n",
        "\n",
        "\n",
        "You could use another dataset to help. What properties should such a dataset have?\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "849bqukwEDGl"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 4</font></summary>\n",
        "\n",
        "Even though the images in ImageNet are not of tumors, natural images contain information on aspects of visual objects that are similar to tumors (that they're coherent, locally smooth, etc)\n",
        "\n",
        "\n",
        "If you train a neural network on ImageNet first so that it learns general vision and embeddings of images, what might you want to change when training on the tumor images dataset?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "bE0Mx3KyEDGl"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for solution</font></summary>\n",
        "\n",
        "Humans don't learn to see when they learn a new classification task. We already have a trained visual system that is good at processing and learning embeddings for natural images.\n",
        "\n",
        "We can replicate this in neural networks! First, we can train our neural network on ImageNet alone to do object classification. This gives us a neural network that has already learned how to process and embed images. \n",
        "\n",
        "Then, we want to take this neural network and continue to train it on just the tumor classification dataset. We can chop off the existing final layer (that outputs the probabilities of all the ImageNet classes) and train a new one that outputs the probability of there being a tumor in the image. \n",
        "\n",
        "We could keep all the weights in the convolutional layers fixed, not allowing them to change after the ImageNet training or *fine-tune* them. People take both strategies!\n",
        "\n",
        "This whole process is called pre-training. We have pre-trained the neural network on ImageNet before training on our actual task, the detection of tumors. \n",
        "\n",
        "We should mention here that there are many ways of doing this. Train the whole network after training on a first task. Train the top layers after training the bottom layers. Potentially first do the latter and then the former. Pre-training can be done in many ways - looking for it as an opportunity is important."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "7wdo4gxOEDGl"
      },
      "outputs": [],
      "source": [
        "# @title Video 6: Detecting Tumors Wrap-up\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"fAD2Bo49LgE\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 6: Detecting Tumors Wrap-up')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "RmdRvMINEDGm"
      },
      "source": [
        "Check out the papers mentioned in the above video:\n",
        "\n",
        "- [Human-computer collaboration for skin cancer recognition ](https://www.nature.com/articles/s41591-020-0942-0)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "eGcRr9OwEDGm"
      },
      "source": [
        "---\n",
        "# Section 4: Brains on Forrest Gump"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "5aCXXY3fEDGn"
      },
      "outputs": [],
      "source": [
        "# @title Video 7: Brains on Forrest Gump Vignette\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"R7H4ybe7gck\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 7: Brains on Forrest Gump Vignette')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "5ADFsX78EDGn"
      },
      "outputs": [],
      "source": [
        "# @title Video 8:  Brains on Forrest Gump Set-up\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"TcBNbGez5BY\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 8:  Brains on Forrest Gump Set-up')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "L8_Ce60oEDGn"
      },
      "source": [
        "Konrad has a great dataset - he has someone watching all of the movie Forrest Gump and MRI data (brain imaging) over the whole time the person is watching the movie. So, basically, he has the video stream over time and the brain data over time. He wants to figure out what those two data streams have in common. In other words, he wants to pull the shared information from two data modalities.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "4cX3mZ61EDGn"
      },
      "source": [
        "## Think! 3: Designing a strategy for pulling shared info about brain data and Forrest Gump\n",
        "\n",
        "Given everything you know, how would you design a strategy to get a shared embedding for the brain and video data? Be specific & write down a procedure.\n",
        "\n",
        "\n",
        "Please discuss as a group. If you get stuck, you can uncover the hints below one at a time. Please spend some time discussing before uncovering the next hint though! You are being real deep learning scientists now and the answers won't be easy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "NeLwawOJEDGn"
      },
      "outputs": [],
      "source": [
        "# @title Student Response\n",
        "from ipywidgets import widgets\n",
        "\n",
        "\n",
        "text=widgets.Textarea(\n",
        "   value='Type your answer here and click on `Submit!`',\n",
        "   placeholder='Type something',\n",
        "   description='',\n",
        "   disabled=False\n",
        ")\n",
        "\n",
        "button = widgets.Button(description=\"Submit!\")\n",
        "\n",
        "display(text,button)\n",
        "\n",
        "def on_button_clicked(b):\n",
        "   atform.add_answer('q3' , text.value)\n",
        "   print(\"Submission successful!\")\n",
        "\n",
        "\n",
        "button.on_click(on_button_clicked)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "Sp_kv1p8EDGo"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 1 </font></summary>\n",
        "\n",
        "We want the two datasets to share something. What does that mean? \n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "BFNSpAt7EDGo"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 2 </font></summary>\n",
        "\n",
        "Where could the vectors $\\bar{X}_1$ and $\\bar{X}_2$ come from? How could they relate to the brain data and video data?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "MrBdmfViEDGo"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 3 </font></summary>\n",
        "\n",
        "You may want to use more than one neural network!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "NVUr1E7AEDGo"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 4 </font></summary>\n",
        "\n",
        "What do we want our neural network solution to do here? Is there anything you want it to maximize or minimize?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "gj4RjI-REDGo"
      },
      "source": [
        "<details>\n",
        "<summary> <font color='green'>Click here for hint 5 </font></summary>\n",
        "\n",
        "What happens if we multiply all activities by 2? We need a scale invariant solution."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "Ab-snRG7EDGo"
      },
      "outputs": [],
      "source": [
        "# @title Video 9: Brains on Forrest Gump Wrap-up\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"5rp9utqRvWY\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 9: Brains on Forrest Gump Wrap-up')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "rG7Z2lXcEDGp"
      },
      "source": [
        "Check out the papers mentioned in the above video:\n",
        "\n",
        "- [Deep Canonical Correlation Analysis ](https://proceedings.mlr.press/v28/andrew13.html)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "mPvxA7A_EDGp"
      },
      "source": [
        "---\n",
        "# Summary"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "MkZffhtgEDGp"
      },
      "outputs": [],
      "source": [
        "# @title Video 10: Wrap up of DL thinking\n",
        "from ipywidgets import widgets\n",
        "\n",
        "out2 = widgets.Output()\n",
        "with out2:\n",
        "  from IPython.display import IFrame\n",
        "  class BiliVideo(IFrame):\n",
        "    def __init__(self, id, page=1, width=400, height=300, **kwargs):\n",
        "      self.id=id\n",
        "      src = \"https://player.bilibili.com/player.html?bvid={0}&page={1}\".format(id, page)\n",
        "      super(BiliVideo, self).__init__(src, width, height, **kwargs)\n",
        "\n",
        "  video = BiliVideo(id=f\"\", width=854, height=480, fs=1)\n",
        "  print(\"Video available at https://www.bilibili.com/video/{0}\".format(video.id))\n",
        "  display(video)\n",
        "\n",
        "out1 = widgets.Output()\n",
        "with out1:\n",
        "  from IPython.display import YouTubeVideo\n",
        "  video = YouTubeVideo(id=f\"p9vQLAfrYJQ\", width=854, height=480, fs=1, rel=0)\n",
        "  print(\"Video available at https://youtube.com/watch?v=\" + video.id)\n",
        "  display(video)\n",
        "\n",
        "out = widgets.Tab([out1, out2])\n",
        "out.set_title(0, 'Youtube')\n",
        "out.set_title(1, 'Bilibili')\n",
        "\n",
        "# add event to airtable\n",
        "atform.add_event('Video 10: Wrap up of DL thinking')\n",
        "\n",
        "display(out)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "execution": {},
        "id": "x8wKgb7uEDGp"
      },
      "source": [
        "In this set of DL Thinks, we saw several tricks on how to do well when there is very limited data we saw:\n",
        "* data augmentation\n",
        "* pretraining\n",
        "* CCA\n",
        "\n",
        "All three can be used in cases where there is limited data available. All three also teach us how the relevant information may be quite clear once we think about it. And how ideas about the world translate into approaches in deep learning."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "execution": {},
        "id": "okvDQs7NEDGp"
      },
      "outputs": [],
      "source": [
        "# @title Airtable Submission Link\n",
        "from IPython import display as IPydisplay\n",
        "IPydisplay.HTML(\n",
        "   f\"\"\"\n",
        " <div>\n",
        "   <a href= \"{atform.url()}\" target=\"_blank\">\n",
        "   <img src=\"https://github.com/NeuromatchAcademy/course-content-dl/blob/main/tutorials/static/SurveyButton.png?raw=1\"\n",
        " alt=\"button link end of day Survey\" style=\"width:410px\"></a>\n",
        "   </div>\"\"\" )"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "W3D2_Tutorial1",
      "provenance": [],
      "toc_visible": true,
      "include_colab_link": true
    },
    "kernel": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}